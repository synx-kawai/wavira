# Wavira Training Configuration
# Usage: config = TrainingConfig.from_yaml("configs/default.yaml")

# Model configuration
n_channels: 3
n_subcarriers: 114
encoder_type: "transformer"  # Options: transformer, lstm, bilstm
hidden_dim: 256
signature_dim: 256
num_layers: 1
dropout: 0.1
nhead: 8

# Training configuration
batch_size: 8
learning_rate: 0.0001
weight_decay: 0.0
epochs: 300
lr_step_size: 50
lr_gamma: 0.95
temperature: 0.07

# Data configuration
sequence_length: 200

# Checkpointing
checkpoint_dir: "checkpoints"
log_interval: 10
eval_interval: 10
save_interval: 50

# Early stopping
early_stopping_patience: 50
early_stopping_min_delta: 0.001

# Logging (requires: pip install wavira[logging])
use_tensorboard: true
tensorboard_log_dir: "runs"
experiment_name: ""  # Leave empty for auto-generated timestamp
